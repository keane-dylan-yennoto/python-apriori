{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' HELPERS '''\n",
    "\n",
    "def sort_dictionary(dictInput: dict):\n",
    "    # sorts dictionary by keys\n",
    "    return {key: val for key, val in sorted(dictInput.items(), key = lambda ele: ele[0])}\n",
    "\n",
    "def generate_no_sups(lk: dict):\n",
    "    # returns keys of dictionary in a list\n",
    "    return [itemSet for itemSet in lk] \n",
    "\n",
    "def filter_data(aprioriResult, minimumSupport):\n",
    "    tempRes = {}\n",
    "    for x in aprioriResult:\n",
    "        miniTempRes = {}\n",
    "        for y in aprioriResult[x]:\n",
    "            if aprioriResult[x][y] >= minimumSupport:\n",
    "                miniTempRes[y] = aprioriResult[x][y]\n",
    "        \n",
    "        tempRes[x] = miniTempRes\n",
    "    \n",
    "    return tempRes\n",
    "\n",
    "def item_set_counter(aprioriResult):\n",
    "    itemSetCount = {}\n",
    "    for kItemSet in aprioriResult:\n",
    "        itemSetCount[kItemSet] = len(aprioriResult[kItemSet])\n",
    "    return itemSetCount\n",
    "\n",
    "'''\n",
    "APRIORI ALGORITHM & HELPERS\n",
    "'''\n",
    "\n",
    "def above_support(dictInput, minSupport):\n",
    "    return {key: val for key, val in dictInput.items() if val >= minSupport}\n",
    "\n",
    "def generate_k_candidate_set(prevLk):\n",
    "    #input of prevLk is a dictionary of key/value pairs where each key is a sorted itemset in the form of tuple\n",
    "\n",
    "    prevLkNoSups = generate_no_sups(prevLk)\n",
    "    ck = {}\n",
    "\n",
    "    upIdx = 0\n",
    "    bottomIdx = 1\n",
    "\n",
    "    while(1):\n",
    "\n",
    "        if (bottomIdx == len(prevLkNoSups)):\n",
    "            upIdx += 1\n",
    "            bottomIdx = upIdx + 1\n",
    "            continue\n",
    "\n",
    "        if upIdx >= len(prevLkNoSups)-1 and bottomIdx >= len(prevLkNoSups)-1:\n",
    "            break\n",
    "        \n",
    "        if prevLkNoSups[upIdx][0:-1] == prevLkNoSups[bottomIdx][0:-1]:\n",
    "            ck[prevLkNoSups[upIdx] + (prevLkNoSups[bottomIdx][-1],)] = 0\n",
    "            # print(upIdx, ' ' , bottomIdx)\n",
    "        else:\n",
    "            # print('----change----')\n",
    "            upIdx += 1\n",
    "            bottomIdx = upIdx + 1\n",
    "            continue\n",
    "        bottomIdx += 1\n",
    "    return ck\n",
    "\n",
    "def prune(ck, prevLk, k):\n",
    "    prunedCk = {}\n",
    "    for itemSet in ck:\n",
    "        if all(subset in prevLk for subset in combinations(itemSet, k-1)):\n",
    "            prunedCk[itemSet] = 0\n",
    "\n",
    "    return prunedCk\n",
    "\n",
    "def count_support(trans, ck, k):\n",
    "    for transaction in trans:\n",
    "        if len(transaction) >= k:\n",
    "            for comb in combinations(transaction,k):\n",
    "                if comb in ck:\n",
    "                    ck[comb] = ck[comb] + 1\n",
    "    return ck\n",
    "\n",
    "def apriori(trans: list, minSupport: float):\n",
    "    \"\"\" \n",
    "    \n",
    "    @param trans: a list of transactions, each transaction is also a list \n",
    "    @param minSupport: minimum support for apriori algorithm\n",
    "   \n",
    "    @return: dictionary of frequent itemsets along with support\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    masterCandidates = {1:{}}\n",
    "\n",
    "    c1 = Counter() \n",
    "    for x in trans:\n",
    "        # gets the data of on one-itemset candidates\n",
    "        c1.update(x)\n",
    "\n",
    "    c1 = sort_dictionary(dict(c1)) \n",
    "\n",
    "    l1 = above_support(c1, minSupport) #get above support\n",
    "    masterCandidates[1] = l1 #add 1-itemset to masterCandidate\n",
    "\n",
    "    c2 = {}\n",
    "    for comb in combinations(l1,2): #generate 2-itemset candidates\n",
    "        c2[comb] = 0\n",
    "\n",
    "    c2 = count_support(trans, c2, 2)\n",
    "\n",
    "    l2 = above_support(c2, minSupport)\n",
    "\n",
    "    lk = l2\n",
    "\n",
    "    k = 3\n",
    "\n",
    "    while(lk):\n",
    "  \n",
    "        masterCandidates[k-1] = lk #add k-itemset to masterCandidate\n",
    "        \n",
    "        ck = generate_k_candidate_set(lk)\n",
    "\n",
    "        ck = prune(ck, lk, k)\n",
    "\n",
    "        ck = count_support(trans, ck, k)\n",
    "\n",
    "        lk = above_support(ck, minSupport)\n",
    "\n",
    "        k = k+1\n",
    "    \n",
    "    return masterCandidates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening Transaction.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was done in a question related to course SDSC3002 Data Mining in City University of Hong Kong\n",
    "\n",
    "The challenge was given a txt file where each line represents a transaction of transaction ids,\n",
    "report the number of frequent patterns, as well as the number of size-k frequent patterns for each size k \n",
    "with at least one frequent pattern, under each setting of minFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trans.txt') as f:\n",
    "    lines = [line.replace('\\t', ' ').strip() for line in f]\n",
    "\n",
    "trans = [sorted(list(map(int, line.split()))) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[21],\n",
       " [768, 787],\n",
       " [789, 796],\n",
       " [802],\n",
       " [3],\n",
       " [44],\n",
       " [1],\n",
       " [1, 74, 96],\n",
       " [110],\n",
       " [614, 777, 790, 803]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[0:10] #the apriori() function takes in a list of transactions, each transaction is a list as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[70.0, 140.0, 209.99999999999997, 280.0, 350.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minFreqs = [0.0005,0.0004,0.0003,0.0002,0.0001] # the given mininum frequencies\n",
    "minFreqs.sort() # sort, explanation of why doing sort is done below\n",
    "minSupports = [x*len(trans) for x in minFreqs] # support = num of transactions * frequency\n",
    "minSupports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Frequency: 0.0001\n",
      "-----------------------------\n",
      "1-itemset: 731\n",
      "2-itemset: 8200\n",
      "3-itemset: 8201\n",
      "4-itemset: 1828\n",
      "5-itemset: 100\n",
      "Total: 19060\n",
      "\n",
      "Minimum Frequency: 0.0002\n",
      "-----------------------------\n",
      "1-itemset: 592\n",
      "2-itemset: 4564\n",
      "3-itemset: 2831\n",
      "4-itemset: 359\n",
      "5-itemset: 5\n",
      "Total: 8351\n",
      "\n",
      "Minimum Frequency: 0.0003\n",
      "-----------------------------\n",
      "1-itemset: 527\n",
      "2-itemset: 3080\n",
      "3-itemset: 1384\n",
      "4-itemset: 134\n",
      "5-itemset: 1\n",
      "Total: 5126\n",
      "\n",
      "Minimum Frequency: 0.0004\n",
      "-----------------------------\n",
      "1-itemset: 474\n",
      "2-itemset: 2258\n",
      "3-itemset: 814\n",
      "4-itemset: 50\n",
      "5-itemset: 0\n",
      "Total: 3596\n",
      "\n",
      "Minimum Frequency: 0.0005\n",
      "-----------------------------\n",
      "1-itemset: 440\n",
      "2-itemset: 1747\n",
      "3-itemset: 525\n",
      "4-itemset: 27\n",
      "5-itemset: 0\n",
      "Total: 2739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ap1 = apriori(trans, minSupports[0]) #running apriori algorithm for minimum frequency of 0.0001\n",
    "\n",
    "masterData = {}\n",
    "masterData[minFreqs[0]] = ap1\n",
    "\n",
    "\n",
    "''' \n",
    "\n",
    "a trick for running the challenge above is instead of running the apriori function for each given minimum frequency, \n",
    "we run the apriori algorithm once with minimum frequency with the lowest value and filter accordingly with the other frequencies.\n",
    "\n",
    "\n",
    "'''\n",
    "for i,x in enumerate(minSupports[1:]):\n",
    "    tempData = filter_data(ap1, x)\n",
    "    masterData[minFreqs[i+1]] = tempData\n",
    "\n",
    "for x in masterData:\n",
    "    print(f'Minimum Frequency: {x}')\n",
    "    print(f'-----------------------------')\n",
    "    currentItemSetCount = item_set_counter(masterData[x])\n",
    "    for y in currentItemSetCount:\n",
    "        print(f'{y}-itemset: {currentItemSetCount[y]}')\n",
    "    total = sum(currentItemSetCount.values())\n",
    "    print(f'Total: {total}')\n",
    "    print(\"\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
